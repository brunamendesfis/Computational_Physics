{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fully Conected Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "input é injetado na caixa preta (rede neural) e da caixa preta sai o output: \\\n",
    "a quantidade de input/output não é fixo \\\n",
    "parâmetros: w (matrizes), b (vetores) \\\n",
    "com o output podemos calcular o erro desse resultado \\\n",
    "minimizar o erro: \\\n",
    "variar os parâmetros w e b \\\n",
    "erro é eessencialmente uma função:\n",
    "f(w, b)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exemplo\n",
    "layer (l): \\\n",
    " l = 0 \\\n",
    " x_0^0 (input 0 da camada 0) e x_0^1 (input 1 da camada 0) \\\n",
    " podemos definir um vetor x_l dessa camada \\\n",
    "Para l = 1, temos: \\\n",
    "x_1^0, x_1^1, x_1^2. Esses x foram o vetor x_1 \\\n",
    "onde cada x de cada camada se conectam entre os layers \\\n",
    "os dados de conexão é feita por 'pesos ou weights': \\\n",
    "w_l^(n->n) \\\n",
    "bias: b \\\n",
    "x_1 = a_1(b_1 + w_1.x_0) (todos são vetores): se refere a uma transfromação linear da conexão entre a camada 0 e 1 \\ \n",
    "onde a são as funções de ativação (é não-linear) \\\n",
    "podemos ter a para cada camada, onde são diferentes uma das outras \\\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a rede neural é a partir da camada l = 1 \\\n",
    "o erro é aplicado na última camada (l = N_l) \\\n",
    "erro = loss (função) \\\n",
    "input: x_0 (dados) e y_0 (previsão) \\\n",
    "output: y_{N_l} "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mean Squared: \n",
    "L = <(y_(N_l) - y_0)^2> \\\n",
    "L = L(x_(N_l)) = L{a_Nl[b_Nl + w_Nl.x_Nl]} \\\n",
    "L = L(b_Nl, w_Nl, x_Nl-1) \\\n",
    "L = L({b_l}, {w_Nl}, x_0, y_0) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mínimo da função:\n",
    "gradiente descendente: derivar a função e ir em sentido contrário a derivada \\\n",
    "usando lei de newton: \\\n",
    "f = - grad(u) \\\n",
    "f = ma \\\n",
    "a = -(1/m)grad(u) \\\n",
    "Passo: \\\n",
    "Deltax = - alphaGrad(u) \\\n",
    "alpha é o learning rates (taxa de aprendizado) \\\n",
    "a escolha do learning rates muda o aprendizado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tarefa:\n",
    "achar o mínimo das funções abaixo usando o método do gradiente descendente \\\n",
    "1) f(x) = x² - 1 e x_0 = 3 \\\n",
    "montar o gráfico dessa função. com as raízes e mostrando os passos com diferentes valores de alpha \\\n",
    "2) pegar a função que o professor forneceu, escolher as raízes e mostrar os passos mostrando o alpha\n",
    "Entrega: ideal entregar na terça, caso não seja possível, entregar até no máximo quinta-feira"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
