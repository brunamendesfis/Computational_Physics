{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ac3a3af7",
   "metadata": {},
   "source": [
    "## Exercício 1\n",
    "\n",
    "Siga o tutorial do site [Physics-informed Neural Networks: a simple tutorial with PyTorch](https://medium.com/@theo.wolf/physics-informed-neural-networks-a-simple-tutorial-with-pytorch-f28a890b874a). Neste exemplo, você irá resolver a EDO do resfriamento de uma caneca de café em etapas:\n",
    "\n",
    "1. Resolva analiticamente a EDO do resfriamento de uma caneca de café. A equação é dada por:\n",
    "\n",
    "```math\n",
    "   \\frac{dT}{dt} = r(T_{amb} - T)\n",
    "```\n",
    "onde $T$ é a temperatura do café, $T_{amb} = 25$ ºC é a temperatura ambiente e $r = 0.005$ 1/s é uma taxa de resfriamento.\n",
    "\n",
    "2. Resolva a EDO usando o método de Runge-Kutta de quarta ordem (RK4) e compare com a solução analítica. Use o comando `scipy.integrate.solve_ivp`.\n",
    "\n",
    "3. Usando a solução analítica, ou RK4, gere dados sintéticos para treinar a PINN. Cerca de 10 pontos no intervalo de 0 a 200 segundos (veja exemplo no tutorial). Some um ruído gaussiano com média 0 e desvio padrão 0.5 em cada ponto.\n",
    "\n",
    "4. Tente usar uma NN de regressão simples para ajustar os dados sintéticos e extrapolar para tempos maiores (até 1000 segundos). Compare com a solução analítica. Sabemos que a extrapolação será péssima.\n",
    "\n",
    "5. Agora, siga o tutorial e implemente a PINN incluindo as restrições físicas na minimização da perda, mas assumindo que conhecemos o valor da taxa $r = 0.005$ 1/s. Compare com a solução analítica e com a NN de regressão simples.\n",
    "\n",
    "6. Ainda seguindo o tutorial, implemente a PINN sem conhecer o valor da taxa $r$. A rede deve ser capaz de descobrir o valor correto. Compare com a solução analítica e com a NN de regressão simples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c4fa717",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5cc42e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad(outputs, inputs):\n",
    "    \"\"\"Computes the partial derivative of an output with respect to an input.\"\"\"\n",
    "    with tf.GradientTape() as tape:\n",
    "        tape.watch(inputs)\n",
    "        grads = tape.gradient(outputs, inputs)\n",
    "    return grads\n",
    "\n",
    "def physics_loss(model, R, Tenv):\n",
    "    \"\"\"The physics loss of the model.\"\"\"\n",
    "    # Create collocation points\n",
    "    ts = tf.linspace(0, 1000, num=1000)[:, tf.newaxis]  # Shape (1000, 1)\n",
    "    ts = tf.Variable(ts, trainable=True)  # Ensure `ts` is differentiable\n",
    "\n",
    "    # Run the collocation points through the network\n",
    "    temps = model(ts)\n",
    "\n",
    "    # Get the gradient\n",
    "    with tf.GradientTape() as tape:\n",
    "        tape.watch(ts)\n",
    "        dT = tape.gradient(temps, ts)\n",
    "\n",
    "    # Compute the ODE\n",
    "    ode = dT - R * (Tenv - temps)\n",
    "\n",
    "    # MSE of ODE\n",
    "    return tf.reduce_mean(tf.square(ode))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "439e1da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(tf.keras.Model):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super(Net, self).__init__(*args, **kwargs)\n",
    "        # Make r a trainable variable\n",
    "        self.r = tf.Variable(0.0, trainable=True, dtype=tf.float32)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # Define the forward pass (to be implemented based on your architecture)\n",
    "        pass\n",
    "\n",
    "def physics_loss_discovery(model, Tenv):\n",
    "    \"\"\"Physics loss for discovering the parameter r.\"\"\"\n",
    "    # Create collocation points\n",
    "    ts = tf.linspace(0, 1000, num=1000)[:, tf.newaxis]  # Shape (1000, 1)\n",
    "    ts = tf.Variable(ts, trainable=True)  # Ensure `ts` is differentiable\n",
    "\n",
    "    # Run the collocation points through the network\n",
    "    temps = model(ts)\n",
    "\n",
    "    # Compute the gradient of temps with respect to ts\n",
    "    with tf.GradientTape() as tape:\n",
    "        tape.watch(ts)\n",
    "        dT = tape.gradient(temps, ts)\n",
    "\n",
    "    # Use the differentiable parameter r\n",
    "    pde = model.r * (Tenv - temps) - dT\n",
    "\n",
    "    # Return the mean squared error of the PDE residual\n",
    "    return tf.reduce_mean(tf.square(pde))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5279287",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
